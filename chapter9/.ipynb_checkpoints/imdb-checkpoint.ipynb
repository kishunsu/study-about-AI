{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMDB 映画レビュー感情分類**\n",
    "\n",
    "感情(肯定/否定)のラベル付けをされた、25,000のIMDB映画レビューのデータセット。レビューは前処理済みで、各レビューは単語のインデックス(整数値)のシーケンスとしてエンコードされている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.layers import Activation, Dense, Embedding, GRU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_features = 5000\n",
    "n_max_len = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.pyenv/versions/3.6.5/lib/python3.6/site-packages/keras/datasets/imdb.py:49: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=n_max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データをいくつか表示してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "(25000,)\n",
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])]\n",
      "141\n",
      "y:\n",
      "(25000,)\n",
      "[1 0 0 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print('X:', X_train.shape, X_train[0:2], sep='\\n')#X_trainはタプル型,タプルの中にlistが入ってる。shapeの(25000,)の,はタプル型を表す\n",
    "print(len(X_train[2]))\n",
    "print('y:', y_train.shape, y_train[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各レビューの単語長が一定になるようにパディング/足切り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=n_max_len)#80とすると意味は？あまりに短すぎると意味ないから適切な長さで切る？次元圧縮??\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=n_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80)\n",
      "X:\n",
      "(25000, 80)\n",
      "[[  15  256    4    2    7 3766    5  723   36   71   43  530  476   26\n",
      "   400  317   46    7    4    2 1029   13  104   88    4  381   15  297\n",
      "    98   32 2071   56   26  141    6  194    2   18    4  226   22   21\n",
      "   134  476   26  480    5  144   30    2   18   51   36   28  224   92\n",
      "    25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
      "  4472  113  103   32   15   16    2   19  178   32]\n",
      " [ 125   68    2    2   15  349  165 4362   98    5    4  228    9   43\n",
      "     2 1157   15  299  120    5  120  174   11  220  175  136   50    9\n",
      "  4373  228    2    5    2  656  245 2350    5    4    2  131  152  491\n",
      "    18    2   32    2 1212   14    9    6  371   78   22  625   64 1382\n",
      "     9    8  168  145   23    4 1690   15   16    4 1355    5   28    6\n",
      "    52  154  462   33   89   78  285   16  145   95]\n",
      " [ 645  662    8  257   85 1200   42 1228 2578   83   68 3912   15   36\n",
      "   165 1539  278   36   69    2  780    8  106   14    2 1338   18    6\n",
      "    22   12  215   28  610   40    6   87  326   23 2300   21   23   22\n",
      "    12  272   40   57   31   11    4   22   47    6 2307   51    9  170\n",
      "    23  595  116  595 1352   13  191   79  638   89    2   14    9    8\n",
      "   106  607  624   35  534    6  227    7  129  113]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print('X:', X_train.shape, X_train[0:3], sep='\\n')\n",
    "#type(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.pyenv/versions/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "/home/ec2-user/.pyenv/versions/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(64, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_max_features, 128, dropout=0.2))\n",
    "model.add(GRU(64, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(Dense(1))#0か1かなので1つだけ\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.pyenv/versions/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 24s 973us/step - loss: 0.5191 - acc: 0.7331 - val_loss: 0.4139 - val_acc: 0.8089\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 24s 941us/step - loss: 0.3853 - acc: 0.8300 - val_loss: 0.3955 - val_acc: 0.8195\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 24s 947us/step - loss: 0.3403 - acc: 0.8555 - val_loss: 0.3818 - val_acc: 0.8306\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 24s 945us/step - loss: 0.3071 - acc: 0.8732 - val_loss: 0.3830 - val_acc: 0.8344\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 24s 943us/step - loss: 0.2698 - acc: 0.8912 - val_loss: 0.4007 - val_acc: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f003f4320>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, nb_epoch=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.40066922830581664\n",
      "Test accuracy: 0.824959999961853\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
